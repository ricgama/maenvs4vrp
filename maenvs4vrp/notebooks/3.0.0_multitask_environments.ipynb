{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10b289ec-6165-40dc-b779-cc645cd138dd",
   "metadata": {},
   "source": [
    "# Multi-Tasking Environments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737e6814-c478-47ba-aca8-2c436eae0060",
   "metadata": {},
   "source": [
    "### Install"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143ae8dd-b559-472b-bbaa-c3f66d601b44",
   "metadata": {},
   "source": [
    "Uncomment the following cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1097f4a7-5053-493d-b9a2-d62441e49a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/ricgama/maenvs4vrp.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65b82c8-1117-4724-be8c-7e252781d39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When using Colab\n",
    "#%cd maenvs4vrp\n",
    "#%mv maenvs4vrp/ repo_temp/\n",
    "#%mv repo_temp/ ..\n",
    "#%cd ..\n",
    "#%cp maenvs4vrp/setup.py repo_temp/\n",
    "#%rm -r maenvs4vrp\n",
    "#%mv repo_temp/ maenvs4vrp/\n",
    "#%cd maenvs4vrp/\n",
    "#!pip install ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de30abc-a2a7-44c6-9d03-560572031cd4",
   "metadata": {},
   "source": [
    "Multi-tasking environments support simulations on multiple variants within the same environment structure, unlike all other environments where one can only simulate a single variant.\n",
    "\n",
    "There is either the possibility of sampling random variants across batches, so that we get an instance with several VRP problems or picking an instance from the list of supported variants.\n",
    "\n",
    "Supported variants are combinations of a set of attributes, which can be enabled or disabled."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1931a419-d771-4261-804d-e4e94c1bbd66",
   "metadata": {},
   "source": [
    "At the moment, **MAENVS4VRP** offers 4 different multi-tasking environments. One base environment and three generalizations.\n",
    "\n",
    "Environments supported are:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c63be8-5690-462f-b033-bd0c9954af30",
   "metadata": {},
   "source": [
    "* MTVRP: Base environment.\n",
    "* GMTVRP: MTVRP generalization with support to online scenarios.\n",
    "* MTDVRP: MTVRP generalization with multiple depots.\n",
    "* GMTDVRP: MTVRP generalization with support to online scenarios and multiple depots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87bf9f9",
   "metadata": {},
   "source": [
    "MTVRP base environment is adapted from [RouteFinder](https://github.com/ai4co/routefinder) environments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8f0756-2bd5-4b61-89fc-5a8abdac5112",
   "metadata": {},
   "source": [
    "## Supported VRP Variants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f5e7e4-3d68-4b4d-aff3-e494bc8cd792",
   "metadata": {},
   "source": [
    "Supported VRP variants are present on the following table. Generalizations use these base variants to introduce extra features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29518af9-56fb-451c-abf1-9aecc640aeec",
   "metadata": {},
   "source": [
    "|Variants         |    Capacity     |   Open Routes   |    Backhaul     | Mixed Problems  | Duration Limits |  Time Windows   |\n",
    "|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|\n",
    "|CVRP             |        ✓        |                 |                 |                 |                 |                 |\n",
    "|OVRP             |        ✓        |        ✓        |                 |                 |                 |                 |\n",
    "|VRPB             |        ✓        |                 |        ✓        |                 |                 |                 |\n",
    "|VRPL             |        ✓        |                 |                 |                 |        ✓        |                 |\n",
    "|VRPTW            |        ✓        |                 |                 |                 |                 |        ✓        |\n",
    "|OVRPTW           |        ✓        |        ✓        |                 |                 |                 |        ✓        |\n",
    "|OVRPB            |        ✓        |        ✓        |        ✓        |                 |                 |                 |\n",
    "|OVRPL            |        ✓        |        ✓        |                 |                 |        ✓        |                 |\n",
    "|VRPBL            |        ✓        |                 |        ✓        |                 |        ✓        |                 |\n",
    "|VRPBTW           |        ✓        |                 |        ✓        |                 |                 |        ✓        |\n",
    "|VRPLTW           |        ✓        |                 |                 |                 |        ✓        |        ✓        |\n",
    "|OVRPBL           |        ✓        |        ✓        |        ✓        |                 |        ✓        |                 |\n",
    "|OVRPBTW          |        ✓        |        ✓        |        ✓        |                 |                 |        ✓        |\n",
    "|OVRPLTW          |        ✓        |        ✓        |                 |                 |        ✓        |        ✓        |\n",
    "|VRPBLTW          |        ✓        |                 |        ✓        |                 |        ✓        |        ✓        |\n",
    "|OVRPBLTW         |        ✓        |        ✓        |        ✓        |                 |        ✓        |        ✓        |\n",
    "|VRPMB            |        ✓        |                 |        ✓        |        ✓        |                 |                 |\n",
    "|OVRPMB           |        ✓        |        ✓        |        ✓        |        ✓        |                 |                 |\n",
    "|VRPMBL           |        ✓        |                 |        ✓        |        ✓        |        ✓        |                 |\n",
    "|VRPMBTW          |        ✓        |                 |        ✓        |        ✓        |                 |        ✓        |\n",
    "|OVRPMBL          |        ✓        |        ✓        |        ✓        |        ✓        |        ✓        |                 |\n",
    "|OVRPMBTW         |        ✓        |        ✓        |        ✓        |        ✓        |                 |        ✓        |\n",
    "|VRPMBLTW         |        ✓        |                 |        ✓        |        ✓        |        ✓        |        ✓        |\n",
    "|OVRPMBLTW        |        ✓        |        ✓        |        ✓        |        ✓        |        ✓        |        ✓        |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7734154-7d0b-41bd-97b4-e6b9ede072ca",
   "metadata": {},
   "source": [
    "## MTVRP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00f404f-b33d-4551-823a-0f4cef363598",
   "metadata": {},
   "source": [
    "Let's explore this base environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8e34f3cb-917a-4605-b851-fcc93d6b53b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from maenvs4vrp.environments.mtvrp.env import Environment\n",
    "from maenvs4vrp.environments.mtvrp.env_agent_selector import AgentSelector\n",
    "from maenvs4vrp.environments.mtvrp.observations import Observations\n",
    "from maenvs4vrp.environments.mtvrp.instances_generator import InstanceGenerator\n",
    "from maenvs4vrp.environments.mtvrp.env_agent_reward import DenseReward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b4f4066a-2178-4f24-b6e8-99f552accd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = InstanceGenerator()\n",
    "obs = Observations()\n",
    "sel = AgentSelector()\n",
    "rew = DenseReward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "cb12d863-ef69-41d0-8e37-1d2cb5cae1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Environment(\n",
    "    instance_generator_object=gen,\n",
    "    obs_builder_object=obs,\n",
    "    agent_selector_object=sel,\n",
    "    reward_evaluator=rew\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c74ba1-b4f1-45cd-8fde-e003eda7fd95",
   "metadata": {},
   "source": [
    "### Sample Random Variants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e655ee0-9f45-4d75-989e-7cdae0239e9c",
   "metadata": {},
   "source": [
    "By default, when ``variant_preset`` is not specified, ``env.reset()`` samples random variants across batches.\n",
    "\n",
    "If ``use_combinations`` is ``True``, attributes are randomly sampled. Otherwise, there's only one attribute per batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6558dbd0-fe5d-4ffb-bead-e90e5ed3e6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "td = env.reset(batch_size=4, num_agents=2, num_nodes=6, use_combinations=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5237ca5a-1076-4e48-805d-1c30f8c24c1e",
   "metadata": {},
   "source": [
    "TensorDict ``env.td_state`` includes all of the problem's parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a99abfd2-a1ce-4631-8b1d-a96bf583a179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        agents: TensorDict(\n",
       "            fields={\n",
       "                active_agents_mask: Tensor(shape=torch.Size([4, 2]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                capacity: Tensor(shape=torch.Size([4, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                cum_ttime: Tensor(shape=torch.Size([4, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                cur_node: Tensor(shape=torch.Size([4, 2]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "                cur_step: Tensor(shape=torch.Size([4, 2]), device=cpu, dtype=torch.int32, is_shared=False),\n",
       "                cur_time: Tensor(shape=torch.Size([4, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                cur_ttime: Tensor(shape=torch.Size([4, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                feasible_nodes: Tensor(shape=torch.Size([4, 2, 6]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                route_length: Tensor(shape=torch.Size([4, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                used_capacity_backhaul: Tensor(shape=torch.Size([4, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                used_capacity_linehaul: Tensor(shape=torch.Size([4, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                visited_nodes: Tensor(shape=torch.Size([4, 2, 6]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "            batch_size=torch.Size([4]),\n",
       "            device=cpu,\n",
       "            is_shared=False),\n",
       "        backhaul_class: Tensor(shape=torch.Size([4, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        backhaul_demands: Tensor(shape=torch.Size([4, 6]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        capacity: Tensor(shape=torch.Size([4, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        coords: Tensor(shape=torch.Size([4, 6, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        cur_agent: TensorDict(\n",
       "            fields={\n",
       "                action_mask: Tensor(shape=torch.Size([4, 6]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                cum_ttime: Tensor(shape=torch.Size([4, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                cur_node: Tensor(shape=torch.Size([4, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "                cur_route_length: Tensor(shape=torch.Size([4, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                cur_step: Tensor(shape=torch.Size([4, 1]), device=cpu, dtype=torch.int32, is_shared=False),\n",
       "                cur_time: Tensor(shape=torch.Size([4, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                cur_ttime: Tensor(shape=torch.Size([4, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                used_capacity_backhaul: Tensor(shape=torch.Size([4, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                used_capacity_linehaul: Tensor(shape=torch.Size([4, 1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "            batch_size=torch.Size([4]),\n",
       "            device=cpu,\n",
       "            is_shared=False),\n",
       "        cur_agent_idx: Tensor(shape=torch.Size([4, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        cur_node_idx: Tensor(shape=torch.Size([4, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        depot_idx: Tensor(shape=torch.Size([4, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        depot_loc: Tensor(shape=torch.Size([4, 1, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        distance_limits: Tensor(shape=torch.Size([4, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        done: Tensor(shape=torch.Size([4]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        end_time: Tensor(shape=torch.Size([4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        has_backhauls: Tensor(shape=torch.Size([4, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        has_distance_limits: Tensor(shape=torch.Size([4, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        has_open_routes: Tensor(shape=torch.Size([4, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        has_time_windows: Tensor(shape=torch.Size([4, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        is_depot: Tensor(shape=torch.Size([4, 6]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        is_last_step: Tensor(shape=torch.Size([4]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        linehaul_demands: Tensor(shape=torch.Size([4, 6]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        max_tour_duration: Tensor(shape=torch.Size([4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        nodes: TensorDict(\n",
       "            fields={\n",
       "                active_nodes_mask: Tensor(shape=torch.Size([4, 6]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                backhaul_demands: Tensor(shape=torch.Size([4, 6]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                distance2depot: Tensor(shape=torch.Size([4, 6]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                linehaul_demands: Tensor(shape=torch.Size([4, 6]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                time2depot: Tensor(shape=torch.Size([4, 6]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "            batch_size=torch.Size([4]),\n",
       "            device=cpu,\n",
       "            is_shared=False),\n",
       "        num_agents: Tensor(shape=torch.Size([4, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        open_routes: Tensor(shape=torch.Size([4, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        original_capacity: Tensor(shape=torch.Size([4, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        service_time: Tensor(shape=torch.Size([4, 6]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        solution: TensorDict(\n",
       "            fields={\n",
       "            },\n",
       "            batch_size=torch.Size([4]),\n",
       "            device=cpu,\n",
       "            is_shared=False),\n",
       "        speed: Tensor(shape=torch.Size([4, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        start_time: Tensor(shape=torch.Size([4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        time_windows: Tensor(shape=torch.Size([4, 6, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        tw_high: Tensor(shape=torch.Size([4, 6]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        tw_low: Tensor(shape=torch.Size([4, 6]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "    batch_size=torch.Size([4]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.td_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ad2e09-7ca1-46aa-8341-d9cb7dc27990",
   "metadata": {},
   "source": [
    "You can check if attributes are present in each batch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63759660-8b56-4722-81a6-b4761d319f2e",
   "metadata": {},
   "source": [
    "Backhauls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "42ae0a00-6097-468e-ad5c-36b067baae18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.td_state['has_backhauls']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ecc9ce68-8b62-4eaf-84d5-4ec27681d5ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 4., 8., 0., 1., 1.],\n",
       "        [0., 3., 1., 0., 0., 8.],\n",
       "        [0., 4., 2., 4., 6., 9.],\n",
       "        [0., 9., 8., 5., 5., 4.]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.td_state['linehaul_demands']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a7c45ed4-5e60-42f2-bc0f-b18f91d5ca9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 5., 0., 0.],\n",
       "        [0., 0., 0., 3., 8., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.td_state['backhaul_demands']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4387414-92cd-4553-9f7e-af310fa8a558",
   "metadata": {},
   "source": [
    "Distance Limits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "895472e5-5e58-4f7e-8435-d46cb711b045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.td_state['has_distance_limits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "acbbbffb-6b05-4cbe-a4b6-3ded603395d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.2786],\n",
       "        [   inf],\n",
       "        [   inf],\n",
       "        [2.4822]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.td_state['distance_limits']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e159123-79ab-470b-b13d-831386ad30f3",
   "metadata": {},
   "source": [
    "Open Routes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "791b989e-0b95-4226-8e5b-f36f035657ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.td_state['has_open_routes']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f2beaf-4c8b-4375-8473-ba28ed49c5ec",
   "metadata": {},
   "source": [
    "Time Windows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "45caac6f-ee49-4b50-befe-9a2765072196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.td_state['has_time_windows']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "84582bad-34f8-4e6b-a007-9e986a5c1f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 4.6000],\n",
       "         [1.4379, 1.6248],\n",
       "         [3.6609, 3.8444],\n",
       "         [2.4875, 2.6786],\n",
       "         [1.2890, 1.4818],\n",
       "         [0.6775, 0.8762]],\n",
       "\n",
       "        [[0.0000,    inf],\n",
       "         [0.0000,    inf],\n",
       "         [0.0000,    inf],\n",
       "         [0.0000,    inf],\n",
       "         [0.0000,    inf],\n",
       "         [0.0000,    inf]],\n",
       "\n",
       "        [[0.0000, 4.6000],\n",
       "         [2.5068, 2.6907],\n",
       "         [1.9209, 2.1087],\n",
       "         [2.4964, 2.6811],\n",
       "         [3.6757, 3.8600],\n",
       "         [2.4038, 2.6037]],\n",
       "\n",
       "        [[0.0000,    inf],\n",
       "         [0.0000,    inf],\n",
       "         [0.0000,    inf],\n",
       "         [0.0000,    inf],\n",
       "         [0.0000,    inf],\n",
       "         [0.0000,    inf]]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.td_state['time_windows']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24ecb66-d8d7-4a19-a02b-579ad8e97a12",
   "metadata": {},
   "source": [
    "### Sample Variant Preset from Presets List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b2d2f3-5991-401e-a56d-5bf5640183d4",
   "metadata": {},
   "source": [
    "Let's consider ``variant_preset`` is ``VRPBL``.\n",
    "\n",
    "If ``use_combinations`` is ``True``, then Backhaul and Distance Limits are not considered into the variant.\n",
    "\n",
    "Otherwise, VRPBL will be represented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "70b57c9f-26e5-47f8-b240-846d25fc2f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "td = env.reset(batch_size=4, num_agents=4, num_nodes=6, use_combinations=False, variant_preset='vrpbl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "dfd0757b-8bee-47a0-af9d-39d71555fb10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.td_state['has_backhauls']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "0898632e-c8cc-4bd0-b7d7-f48ae40a2f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.td_state['has_distance_limits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "572d67d9-3d13-45d4-b86f-78c3712b8222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.td_state['has_open_routes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "9873a186-a5d6-4a50-863f-70521d5ffd3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.td_state['has_time_windows']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8569e31-faaf-4ea9-9224-8d9e7fbdaefc",
   "metadata": {},
   "source": [
    "### Problem Simulation Cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d20035-46e2-4240-8394-d6a315d51ac5",
   "metadata": {},
   "source": [
    "Problem simulation cycle has two different parts:\n",
    "* ``sample_action()``: An action is randomly sampled to the agent according to the action mask present in ``env.td_state``.\n",
    "* ``step()``: The environment's parameters are updated according to its actions.\n",
    "\n",
    "The simulation ends when all ``td['done']`` keys become ``True``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "0862e282-1009-4e2a-ad74-b8d8e2af7ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td['done']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "024a66b2-343e-495b-b98d-3c8c7f491785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env step number: 1, active agent name: tensor([[1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]])\n",
      "env step number: 2, active agent name: tensor([[1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]])\n",
      "env step number: 3, active agent name: tensor([[1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1]])\n",
      "env step number: 4, active agent name: tensor([[2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]])\n",
      "env step number: 5, active agent name: tensor([[2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1]])\n",
      "env step number: 6, active agent name: tensor([[2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2]])\n",
      "env step number: 7, active agent name: tensor([[3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3]])\n",
      "env step number: 8, active agent name: tensor([[0],\n",
      "        [3],\n",
      "        [0],\n",
      "        [0]])\n",
      "env step number: 9, active agent name: tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]])\n"
     ]
    }
   ],
   "source": [
    "while not td[\"done\"].all():\n",
    "    td = env.sample_action(td)\n",
    "    td = env.step(td)\n",
    "    step = env.env_nsteps\n",
    "    cur_agent_idx = td['cur_agent_idx']\n",
    "    print(f'env step number: {step}, active agent name: {cur_agent_idx}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9a981d82-bc67-4b55-9dc5-15bec0eaefb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td['done']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8278792a-c39e-4981-bd6d-4a81eb3f3498",
   "metadata": {},
   "source": [
    "## GMTVRP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c883796-d271-45f1-8606-6ec743789e77",
   "metadata": {},
   "source": [
    "In the standard MTVRP setup, the vehicle’s linehaul and backhaul loads aren’t known until the episode ends, which isn’t practical for modeling real‑time operations. To address this, we created the GMTVRP environment, where each vehicle’s load is specified up front at the start of the episode. Let’s dive in:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "3946d8c8-2e39-4e5d-97ca-8fa0438baabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from maenvs4vrp.environments.gmtvrp.env import Environment\n",
    "from maenvs4vrp.environments.gmtvrp.env_agent_selector import SmallestTimeAgentSelector\n",
    "from maenvs4vrp.environments.gmtvrp.observations import Observations\n",
    "from maenvs4vrp.environments.gmtvrp.instances_generator import InstanceGenerator\n",
    "from maenvs4vrp.environments.gmtvrp.env_agent_reward import DenseReward\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5331c202",
   "metadata": {},
   "source": [
    "**Note:** If we want to simulate an online scenario, we have to make sure to instantiate ``SmallestTimeAgentSelector`` as our Agent Selector class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "33663704-a942-4697-80c5-08d75fc1bd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = InstanceGenerator()\n",
    "obs = Observations()\n",
    "sel = SmallestTimeAgentSelector()\n",
    "rew = DenseReward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "bc04c353-98b4-4544-9445-3ec71de1484f",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Environment(\n",
    "    instance_generator_object=gen,\n",
    "    obs_builder_object=obs,\n",
    "    agent_selector_object=sel,\n",
    "    reward_evaluator=rew\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b865fc3-e9df-4ef9-a5e0-a54c0afa4b4d",
   "metadata": {},
   "source": [
    "### Initial Load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ebe3a5-bc3a-4371-b00e-b1228583c792",
   "metadata": {},
   "source": [
    "As previously stated, on MTVRP simulations, agents' load is implicit. In order to support online scenarios, initial load must be defined from the beggining of the route. It can be done in 2 ways:\n",
    "* Sampling a random initial load through ``env.sample_initial_load()`` method.\n",
    "* Defining a custom initial load on ``env.reset()``\n",
    "\n",
    "The method ``env.set_initial_load()`` must always be called, because it will set the initial load present in key ``td['initial_load']``."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a167de6e-22dc-4324-a2f7-ab1a9f12aa41",
   "metadata": {},
   "source": [
    "### Sample Initial Load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17621d6-ac6e-44f0-b88a-8a6e199adc36",
   "metadata": {},
   "source": [
    "It samples values between 0 and agents' maximum capacity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "db94a798-e374-48cf-ae86-7be882cb8883",
   "metadata": {},
   "outputs": [],
   "source": [
    "td = env.reset(batch_size=4, num_agents=2, num_nodes=6, use_combinations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "6a42eab6-d508-4dc3-be87-bcd7556374b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[30.],\n",
       "        [30.],\n",
       "        [30.],\n",
       "        [30.]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.td_state['capacity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e1d9d7c9-3487-4a4f-9662-e89104a46ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "td = env.sample_initial_load(td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "181219ae-30a1-46fc-91e9-cf096ff01e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[21.6385, 21.7317],\n",
       "        [21.6329,  7.6351],\n",
       "        [18.1970, 26.6878],\n",
       "        [ 9.6124,  4.6757]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td['initial_load']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "d9a83d5f-4906-4512-b6a2-230e2bf4f134",
   "metadata": {},
   "outputs": [],
   "source": [
    "td = env.set_initial_load(td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "5502a8c7-04ae-4105-9755-c0f9c42bcfed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[21.6385, 21.7317],\n",
       "        [21.6329,  7.6351],\n",
       "        [18.1970, 26.6878],\n",
       "        [ 9.6124,  4.6757]])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.td_state['agents']['cur_linehaul_load']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282ad3b4-980d-4828-9f14-3c37f671245d",
   "metadata": {},
   "source": [
    "### Set Custom Initial Load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0016813f-d6c8-478c-b046-3029147a0b5f",
   "metadata": {},
   "source": [
    "Defined on ``env.reset()`` arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "53b47d19-0a00-4100-86c0-4833b5286d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "td = env.reset(batch_size=4, num_agents=2, num_nodes=6, use_combinations=True, initial_load=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d86b7182-7517-4f75-836a-07431086c1f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20., 20.],\n",
       "        [20., 20.],\n",
       "        [20., 20.],\n",
       "        [20., 20.]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td['initial_load']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "2291c619-dc2c-47b5-9947-e6d0a967c4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "td = env.set_initial_load(td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "87734a01-a6a6-45b9-9e5f-38b27fa855d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20., 20.],\n",
       "        [20., 20.],\n",
       "        [20., 20.],\n",
       "        [20., 20.]])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.td_state['agents']['cur_linehaul_load']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d80ba8-f9cb-4f01-93a6-bc0f3a359f45",
   "metadata": {},
   "source": [
    "## MTDVRP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d43da07-c960-4158-978a-16f89103ad63",
   "metadata": {},
   "source": [
    "Let's now explore multidepot environments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b2ab7acc-5c0c-4538-90e3-e5ef95d7e727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from maenvs4vrp.environments.mtdvrp.env import Environment\n",
    "from maenvs4vrp.environments.mtdvrp.env_agent_selector import AgentSelector\n",
    "from maenvs4vrp.environments.mtdvrp.observations import Observations\n",
    "from maenvs4vrp.environments.mtdvrp.instances_generator import InstanceGenerator\n",
    "from maenvs4vrp.environments.mtdvrp.env_agent_reward import DenseReward\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "34552945-174f-4595-ae2a-8d6d4eef32ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = InstanceGenerator()\n",
    "obs = Observations()\n",
    "sel = AgentSelector()\n",
    "rew = DenseReward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "834c9c6f-c05a-4602-96f0-ac012774d7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Environment(\n",
    "    instance_generator_object=gen,\n",
    "    obs_builder_object=obs,\n",
    "    agent_selector_object=sel,\n",
    "    reward_evaluator=rew\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc94d96a-5cd6-4dca-b07e-c62066e23368",
   "metadata": {},
   "source": [
    "### Multiple Depots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3792db54-4e4e-4d82-91f8-e03054b7e60b",
   "metadata": {},
   "source": [
    "In order to include multiple depots into the simulation, they must defined on ``env.reset()``. The total number of agents will be the product of the numbers of depots and the defined number of agents.\n",
    "\n",
    "Ex: If ``num_depots = 3`` and ``num_agents  = 5``, the total number of agents will be ``15``. That means each depot will have ``5`` agents associated.\n",
    "\n",
    "Each agent will be assigned to its depot sequentially. So, first agent will be assigned to depot 0, segond agent assigned to depot 1, etc. Every agent must start and end the route at its own depot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "e5965e1a-e6c3-4540-bd9c-dba1cf6d4b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "td = env.reset(batch_size=3, num_agents=5, num_depots=3, num_nodes=24, use_combinations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "11dd1216-0bdd-4dda-9052-553ad8492c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [0, 1, 2],\n",
       "        [0, 1, 2]])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.td_state['depot_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "66da39e4-49dd-4a3c-8bcd-a3303f9c86cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2],\n",
       "        [0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2],\n",
       "        [0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2]])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.td_state['agents']['depot_idx']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e669e1e-73b2-40ea-92b4-32190269b644",
   "metadata": {},
   "source": [
    "After a simulation is run, agents' actions must be starting and ending at their depot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "81de5de4-6e08-4ef0-9eb4-fabc13b8945c",
   "metadata": {},
   "outputs": [],
   "source": [
    "while not td[\"done\"].all():\n",
    "    td = env.sample_action(td)\n",
    "    td = env.step(td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "3fd09787-abb0-4956-9c4a-382ccba13dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  1,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  3,  3,  4,\n",
       "          4,  4,  4,  4,  4,  4,  5,  5,  6,  6,  7,  8,  9, 10, 11, 12, 13, 14],\n",
       "        [ 0,  0,  0,  0,  1,  1,  1,  2,  2,  3,  3,  3,  4,  4,  4,  5,  5,  5,\n",
       "          5,  6,  6,  6,  7,  7,  8,  8,  9,  9,  9, 10, 11, 11, 12, 12, 13, 14],\n",
       "        [ 0,  0,  0,  1,  1,  1,  2,  2,  2,  2,  3,  3,  3,  4,  4,  4,  5,  5,\n",
       "          6,  6,  7,  7,  7,  8,  8,  8,  9, 10, 10, 11, 11, 11, 12, 13, 14,  0]])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.td_state['solution']['agents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "94a6cae3-f076-491a-af14-a6452f1f9757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0, 15, 16, 14, 13, 20,  9,  1, 21,  4, 22,  3, 18,  6,  2, 11,  0, 10,\n",
       "         17,  5,  8,  7, 19,  1, 23,  2, 12,  0,  1,  2,  0,  1,  2,  0,  1,  2],\n",
       "        [18,  4, 23,  0, 10, 20,  1, 11,  2,  8, 19,  0,  7,  5,  1,  6, 22, 16,\n",
       "          2, 12, 15,  0, 21,  1, 13,  2,  3,  9,  0,  1, 14,  2, 17,  0,  1,  2],\n",
       "        [16, 14,  0, 12,  8,  1,  9, 10, 22,  2,  7,  5,  0, 13,  4,  1, 18,  2,\n",
       "         21,  0, 20, 17,  1,  3, 15,  2,  0, 23,  1,  6, 19,  2,  0,  1,  2,  0]])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.td_state['solution']['actions']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d344fed-c26e-4cd2-ae9a-33f3753c18dc",
   "metadata": {},
   "source": [
    "## GMTDVRP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c75a75d-a66a-4bf4-b6b6-ff3cdc013363",
   "metadata": {},
   "source": [
    "Here, it's possible to combine an online scenario and multiple depots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "82d038c9-fe4d-4fa6-a65c-f5f7f6650356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from maenvs4vrp.environments.gmtdvrp.env import Environment\n",
    "from maenvs4vrp.environments.gmtdvrp.env_agent_selector import AgentSelector\n",
    "from maenvs4vrp.environments.gmtdvrp.observations import Observations\n",
    "from maenvs4vrp.environments.gmtdvrp.instances_generator import InstanceGenerator\n",
    "from maenvs4vrp.environments.gmtdvrp.env_agent_reward import DenseReward\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "b45fb62c-9bb1-47cf-8344-008872684e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = InstanceGenerator()\n",
    "obs = Observations()\n",
    "sel = AgentSelector()\n",
    "rew = DenseReward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "ff686c9b-953a-4654-b0e7-2df47a29addf",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Environment(\n",
    "    instance_generator_object=gen,\n",
    "    obs_builder_object=obs,\n",
    "    agent_selector_object=sel,\n",
    "    reward_evaluator=rew\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "861bf22e-e638-4a24-86f2-8de7191ab3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "td = env.reset(batch_size=3, num_agents=5, num_depots=3, num_nodes=24, use_combinations=True, initial_load=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "2e6f971a-c10d-41bf-89cc-7d2380eca27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "td = env.set_initial_load(td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "dde24692-44e1-4227-81d9-8efbfa188c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15.,\n",
       "         15.],\n",
       "        [15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15.,\n",
       "         15.],\n",
       "        [15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15.,\n",
       "         15.]])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.td_state['agents']['cur_linehaul_load']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "b5ec4d54-0c0e-4482-9ba2-b9bf42221a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [0, 1, 2],\n",
       "        [0, 1, 2]])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.td_state['depot_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "361d7211-99f8-49d3-a551-9d2ffb835d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2],\n",
       "        [0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2],\n",
       "        [0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2]])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.td_state['agents']['depot_idx']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e726f6c-97fb-4ab7-b10f-6d20d0fb217f",
   "metadata": {},
   "source": [
    "## Acknowledgements: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a35a010-98f4-40e8-9517-1ab7bb904956",
   "metadata": {},
   "source": [
    "* https://github.com/ai4co/routefinder - checkout their paper:\n",
    "[\"RouteFinder: Towards Foundation Models for Vehicle Routing Problems\"](https://arxiv.org/abs/2406.15007) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maenvs4vrp",
   "language": "python",
   "name": "maenvs4vrp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
