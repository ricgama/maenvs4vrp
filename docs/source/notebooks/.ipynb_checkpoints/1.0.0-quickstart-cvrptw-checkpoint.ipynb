{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d512ff36-4561-406a-88ff-ad32c2fbc897",
   "metadata": {},
   "source": [
    "# Quick start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60cd1bd",
   "metadata": {},
   "source": [
    "## Basic usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e419715",
   "metadata": {},
   "source": [
    "Let's explore the library using the CVRPTW environment as an example. Our API structure is inspired on [PettingZoo](https://pettingzoo.farama.org/), following the Agent Environment Cycle (AEC) philosophy. We have been also greatly influenced by [Flatland](https://flatland.aicrowd.com/intro.html) environment library, and we chose to adopt some of its design principles.\n",
    "\n",
    "make ref to TorchRL - TensorDic and rl4co "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23a2e7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vrpmaenvs.environments.cvrptw.env import Environment\n",
    "from vrpmaenvs.environments.cvrptw.env_agent_selector import AgentSelector\n",
    "from vrpmaenvs.environments.cvrptw.observations import Observations\n",
    "from vrpmaenvs.environments.cvrptw.instances_generator import InstanceGenerator\n",
    "from vrpmaenvs.environments.cvrptw.env_agent_reward import DenseReward\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bed5fbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = InstanceGenerator(batch_size = 8)\n",
    "obs = Observations()\n",
    "sel = AgentSelector()\n",
    "rew = DenseReward()\n",
    "\n",
    "env = Environment(instance_generator_object=gen,  \n",
    "                  obs_builder_object=obs,\n",
    "                  agent_selector_object=sel,\n",
    "                  reward_evaluator=rew,\n",
    "                  seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f300c7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        cur_agent_idx: Tensor(shape=torch.Size([8, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        done: Tensor(shape=torch.Size([8]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        observations: TensorDict(\n",
       "            fields={\n",
       "                action_mask: Tensor(shape=torch.Size([8, 16]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                agent_obs: Tensor(shape=torch.Size([8, 4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                agents_mask: Tensor(shape=torch.Size([8, 4]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                global_obs: Tensor(shape=torch.Size([8, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                node_dynamic_obs: Tensor(shape=torch.Size([8, 16, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                node_static_obs: Tensor(shape=torch.Size([8, 16, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                other_agents_obs: Tensor(shape=torch.Size([8, 4, 3]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "            batch_size=torch.Size([8]),\n",
       "            device=cpu,\n",
       "            is_shared=False),\n",
       "        penalty: Tensor(shape=torch.Size([8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        reward: Tensor(shape=torch.Size([8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        step: Tensor(shape=torch.Size([8, 1]), device=cpu, dtype=torch.int64, is_shared=False)},\n",
       "    batch_size=torch.Size([8]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td = env.reset(batch_size = 8, num_agents=4, num_nodes=16)\n",
    "td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29da80bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "while not td[\"done\"].all():  \n",
    "    td = env.sample_action(td) # this is where we insert our policy\n",
    "    td = env.step(td)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755f3386",
   "metadata": {},
   "source": [
    "## Quick walkthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae4d0ba",
   "metadata": {},
   "source": [
    "Let's now go through the library's building blocks, exploring their functionalities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dc26a8",
   "metadata": {},
   "source": [
    "### Instance generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e451a64f",
   "metadata": {},
   "source": [
    "We can generate instances using one of the two available methods `InstanceGenerator` and `BenchmarkInstanceGenerator`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d93b0219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vrpmaenvs.environments.cvrptw.instances_generator import InstanceGenerator\n",
    "from vrpmaenvs.environments.cvrptw.benchmark_instances_generator import BenchmarkInstanceGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f2261c",
   "metadata": {},
   "source": [
    "#### Random generated instances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b623a211",
   "metadata": {},
   "source": [
    "Random instances are generated following:\n",
    "\n",
    "Li, S., Yan, Z., & Wu, C. (2021). [Learning to delegate for large-scale vehicle routing](https://proceedings.neurips.cc/paper/2021/hash/dc9fa5f217a1e57b8a6adeb065560b38-Abstract.html). Advances in Neural Information Processing Systems, 34, 26198-26211."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "244b3e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = InstanceGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1da42b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "instance = generator.sample_instance(num_agents=2, num_nodes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0b10f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['name', 'num_nodes', 'num_agents', 'data'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f77204e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'random_instance',\n",
       " 'num_nodes': 10,\n",
       " 'num_agents': 2,\n",
       " 'data': TensorDict(\n",
       "     fields={\n",
       "         capacity: Tensor(shape=torch.Size([1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "         coords: Tensor(shape=torch.Size([1, 10, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "         demands: Tensor(shape=torch.Size([1, 10]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "         depot_idx: Tensor(shape=torch.Size([1, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "         end_time: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "         is_depot: Tensor(shape=torch.Size([1, 10]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "         service_time: Tensor(shape=torch.Size([1, 10]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "         start_time: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "         tw_high: Tensor(shape=torch.Size([1, 10]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "         tw_low: Tensor(shape=torch.Size([1, 10]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "     batch_size=torch.Size([1]),\n",
       "     device=cpu,\n",
       "     is_shared=False)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a32f1ee",
   "metadata": {},
   "source": [
    "It's possible to load a set of pre-generaded instances, to be used as validation/test sets. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e681fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_of_instances = set(generator.get_list_of_benchmark_instances()['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e82737b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = InstanceGenerator(instance_type='validation', set_of_instances=set_of_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b15974d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_val_servs_25_agents_10_38\n"
     ]
    }
   ],
   "source": [
    "instance = generator.sample_instance()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2badb78b",
   "metadata": {},
   "source": [
    "Let's check instance dict keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2a1c474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['name', 'num_nodes', 'num_agents', 'data'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b966652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'generated_val_servs_25_agents_10_38'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab722ca0",
   "metadata": {},
   "source": [
    "#### Benchmark instances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9de3909",
   "metadata": {},
   "source": [
    "In order to narrow the current gap between the test beds for algorithm benchmarking used in RL\n",
    "and OR communities, the library allows a straightforward integration of classical OR benchmark\n",
    "instances. For example, we can load a set of classical benchmark instances. Let's see what benchmark instances we have for the CVPTW:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36ae69eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Solomon': ['R103',\n",
       "  'C101',\n",
       "  'C102',\n",
       "  'C103',\n",
       "  'C104',\n",
       "  'C105',\n",
       "  'C106',\n",
       "  'C107',\n",
       "  'C108',\n",
       "  'C109',\n",
       "  'C201',\n",
       "  'C202',\n",
       "  'C203',\n",
       "  'C204',\n",
       "  'C205',\n",
       "  'C206',\n",
       "  'C207',\n",
       "  'C208',\n",
       "  'R101',\n",
       "  'R102',\n",
       "  'R104',\n",
       "  'R105',\n",
       "  'R106',\n",
       "  'R107',\n",
       "  'R108',\n",
       "  'R109',\n",
       "  'R110',\n",
       "  'R111',\n",
       "  'R112',\n",
       "  'R201',\n",
       "  'R202',\n",
       "  'R203',\n",
       "  'R204',\n",
       "  'R205',\n",
       "  'R206',\n",
       "  'R207',\n",
       "  'R208',\n",
       "  'R209',\n",
       "  'R210',\n",
       "  'R211',\n",
       "  'RC101',\n",
       "  'RC102',\n",
       "  'RC103',\n",
       "  'RC104',\n",
       "  'RC105',\n",
       "  'RC106',\n",
       "  'RC107',\n",
       "  'RC108',\n",
       "  'RC201',\n",
       "  'RC202',\n",
       "  'RC203',\n",
       "  'RC204',\n",
       "  'RC205',\n",
       "  'RC206',\n",
       "  'RC207',\n",
       "  'RC208'],\n",
       " 'Homberger': ['C1_10_1',\n",
       "  'C1_10_10',\n",
       "  'C1_10_2',\n",
       "  'C1_10_3',\n",
       "  'C1_10_4',\n",
       "  'C1_10_5',\n",
       "  'C1_10_6',\n",
       "  'C1_10_7',\n",
       "  'C1_10_8',\n",
       "  'C1_10_9',\n",
       "  'C1_2_1',\n",
       "  'C1_2_10',\n",
       "  'C1_2_2',\n",
       "  'C1_2_3',\n",
       "  'C1_2_4',\n",
       "  'C1_2_5',\n",
       "  'C1_2_6',\n",
       "  'C1_2_7',\n",
       "  'C1_2_8',\n",
       "  'C1_4_1',\n",
       "  'C1_4_10',\n",
       "  'C1_4_2',\n",
       "  'C1_4_3',\n",
       "  'C1_4_4',\n",
       "  'C1_4_5',\n",
       "  'C1_4_6',\n",
       "  'C1_4_7',\n",
       "  'C1_4_8',\n",
       "  'C1_4_9',\n",
       "  'C1_6_1',\n",
       "  'C1_6_10',\n",
       "  'C1_6_2',\n",
       "  'C1_6_3',\n",
       "  'C1_6_4',\n",
       "  'C1_6_5',\n",
       "  'C1_6_6',\n",
       "  'C1_6_7',\n",
       "  'C1_6_8',\n",
       "  'C1_8_1',\n",
       "  'C1_8_10',\n",
       "  'C1_8_2',\n",
       "  'C1_8_3',\n",
       "  'C1_8_4',\n",
       "  'C1_8_5',\n",
       "  'C1_8_6',\n",
       "  'C1_8_7',\n",
       "  'C1_8_8',\n",
       "  'C1_8_9',\n",
       "  'C2_10_1',\n",
       "  'C2_10_10',\n",
       "  'C2_10_2',\n",
       "  'C2_10_3',\n",
       "  'C2_10_4',\n",
       "  'C2_10_5',\n",
       "  'C2_10_6',\n",
       "  'C2_10_7',\n",
       "  'C2_10_8',\n",
       "  'C2_2_1',\n",
       "  'C2_2_10',\n",
       "  'C2_2_2',\n",
       "  'C2_2_3',\n",
       "  'C2_2_4',\n",
       "  'C2_2_5',\n",
       "  'C2_2_6',\n",
       "  'C2_2_7',\n",
       "  'C2_2_8',\n",
       "  'C2_2_9',\n",
       "  'C2_4_1',\n",
       "  'C2_4_10',\n",
       "  'C2_4_2',\n",
       "  'C2_4_3',\n",
       "  'C2_4_4',\n",
       "  'C2_4_5',\n",
       "  'C2_4_6',\n",
       "  'C2_4_7',\n",
       "  'C2_4_8',\n",
       "  'C2_6_1',\n",
       "  'C2_6_10',\n",
       "  'C2_6_2',\n",
       "  'C2_6_3',\n",
       "  'C2_6_4',\n",
       "  'C2_6_5',\n",
       "  'C2_6_6',\n",
       "  'C2_6_7',\n",
       "  'C2_6_8',\n",
       "  'C2_6_9',\n",
       "  'C2_8_1',\n",
       "  'C2_8_10',\n",
       "  'C2_8_2',\n",
       "  'C2_8_3',\n",
       "  'C2_8_4',\n",
       "  'C2_8_5',\n",
       "  'C2_8_6',\n",
       "  'C2_8_7',\n",
       "  'C2_8_8',\n",
       "  'C1_2_9',\n",
       "  'C1_6_9',\n",
       "  'C2_10_9',\n",
       "  'C2_4_9',\n",
       "  'C2_8_9',\n",
       "  'R1_2_9',\n",
       "  'R1_6_9',\n",
       "  'R2_10_9',\n",
       "  'R2_4_9',\n",
       "  'R2_8_8',\n",
       "  'RC1_2_7',\n",
       "  'RC1_6_6',\n",
       "  'RC2_10_5',\n",
       "  'RC2_4_5',\n",
       "  'R1_10_1',\n",
       "  'R1_10_10',\n",
       "  'R1_10_2',\n",
       "  'R1_10_3',\n",
       "  'R1_10_4',\n",
       "  'R1_10_5',\n",
       "  'R1_10_6',\n",
       "  'R1_10_7',\n",
       "  'R1_10_8',\n",
       "  'R1_10_9',\n",
       "  'R1_2_1',\n",
       "  'R1_2_10',\n",
       "  'R1_2_2',\n",
       "  'R1_2_3',\n",
       "  'R1_2_4',\n",
       "  'R1_2_5',\n",
       "  'R1_2_6',\n",
       "  'R1_2_7',\n",
       "  'R1_2_8',\n",
       "  'R1_4_1',\n",
       "  'R1_4_10',\n",
       "  'R1_4_2',\n",
       "  'R1_4_3',\n",
       "  'R1_4_4',\n",
       "  'R1_4_5',\n",
       "  'R1_4_6',\n",
       "  'R1_4_7',\n",
       "  'R1_4_8',\n",
       "  'R1_4_9',\n",
       "  'R1_6_1',\n",
       "  'R1_6_10',\n",
       "  'R1_6_2',\n",
       "  'R1_6_3',\n",
       "  'R1_6_4',\n",
       "  'R1_6_5',\n",
       "  'R1_6_6',\n",
       "  'R1_6_7',\n",
       "  'R1_6_8',\n",
       "  'R1_8_1',\n",
       "  'R1_8_10',\n",
       "  'R1_8_2',\n",
       "  'R1_8_3',\n",
       "  'R1_8_4',\n",
       "  'R1_8_5',\n",
       "  'R1_8_6',\n",
       "  'R1_8_7',\n",
       "  'R1_8_8',\n",
       "  'R1_8_9',\n",
       "  'R2_10_1',\n",
       "  'R2_10_10',\n",
       "  'R2_10_2',\n",
       "  'R2_10_3',\n",
       "  'R2_10_4',\n",
       "  'R2_10_5',\n",
       "  'R2_10_6',\n",
       "  'R2_10_7',\n",
       "  'R2_10_8',\n",
       "  'R2_2_1',\n",
       "  'R2_2_10',\n",
       "  'R2_2_2',\n",
       "  'R2_2_3',\n",
       "  'R2_2_4',\n",
       "  'R2_2_5',\n",
       "  'R2_2_6',\n",
       "  'R2_2_7',\n",
       "  'R2_2_8',\n",
       "  'R2_2_9',\n",
       "  'R2_4_1',\n",
       "  'R2_4_10',\n",
       "  'R2_4_2',\n",
       "  'R2_4_3',\n",
       "  'R2_4_4',\n",
       "  'R2_4_5',\n",
       "  'R2_4_6',\n",
       "  'R2_4_7',\n",
       "  'R2_4_8',\n",
       "  'R2_6_1',\n",
       "  'R2_6_10',\n",
       "  'R2_6_2',\n",
       "  'R2_6_3',\n",
       "  'R2_6_4',\n",
       "  'R2_6_5',\n",
       "  'R2_6_6',\n",
       "  'R2_6_7',\n",
       "  'R2_6_8',\n",
       "  'R2_6_9',\n",
       "  'R2_8_1',\n",
       "  'R2_8_10',\n",
       "  'R2_8_2',\n",
       "  'R2_8_3',\n",
       "  'R2_8_4',\n",
       "  'R2_8_5',\n",
       "  'R2_8_6',\n",
       "  'R2_8_7',\n",
       "  'R2_8_9',\n",
       "  'RC1_10_1',\n",
       "  'RC1_10_10',\n",
       "  'RC1_10_2',\n",
       "  'RC1_10_3',\n",
       "  'RC1_10_4',\n",
       "  'RC1_10_5',\n",
       "  'RC1_10_6',\n",
       "  'RC1_10_7',\n",
       "  'RC1_10_8',\n",
       "  'RC1_10_9',\n",
       "  'RC1_2_1',\n",
       "  'RC1_2_10',\n",
       "  'RC1_2_2',\n",
       "  'RC1_2_3',\n",
       "  'RC1_2_4',\n",
       "  'RC1_2_5',\n",
       "  'RC1_2_6',\n",
       "  'RC1_2_8',\n",
       "  'RC1_2_9',\n",
       "  'RC1_4_1',\n",
       "  'RC1_4_10',\n",
       "  'RC1_4_2',\n",
       "  'RC1_4_3',\n",
       "  'RC1_4_4',\n",
       "  'RC1_4_5',\n",
       "  'RC1_4_6',\n",
       "  'RC1_4_7',\n",
       "  'RC1_4_8',\n",
       "  'RC1_4_9',\n",
       "  'RC1_6_1',\n",
       "  'RC1_6_10',\n",
       "  'RC1_6_2',\n",
       "  'RC1_6_3',\n",
       "  'RC1_6_4',\n",
       "  'RC1_6_5',\n",
       "  'RC1_6_7',\n",
       "  'RC1_6_8',\n",
       "  'RC1_6_9',\n",
       "  'RC1_8_1',\n",
       "  'RC1_8_10',\n",
       "  'RC1_8_2',\n",
       "  'RC1_8_3',\n",
       "  'RC1_8_4',\n",
       "  'RC1_8_5',\n",
       "  'RC1_8_6',\n",
       "  'RC1_8_7',\n",
       "  'RC1_8_8',\n",
       "  'RC1_8_9',\n",
       "  'RC2_10_1',\n",
       "  'RC2_10_10',\n",
       "  'RC2_10_2',\n",
       "  'RC2_10_3',\n",
       "  'RC2_10_4',\n",
       "  'RC2_10_6',\n",
       "  'RC2_10_7',\n",
       "  'RC2_10_8',\n",
       "  'RC2_10_9',\n",
       "  'RC2_2_1',\n",
       "  'RC2_2_10',\n",
       "  'RC2_2_2',\n",
       "  'RC2_2_3',\n",
       "  'RC2_2_4',\n",
       "  'RC2_2_5',\n",
       "  'RC2_2_6',\n",
       "  'RC2_2_7',\n",
       "  'RC2_2_8',\n",
       "  'RC2_2_9',\n",
       "  'RC2_4_1',\n",
       "  'RC2_4_10',\n",
       "  'RC2_4_2',\n",
       "  'RC2_4_3',\n",
       "  'RC2_4_4',\n",
       "  'RC2_4_6',\n",
       "  'RC2_4_7',\n",
       "  'RC2_4_8',\n",
       "  'RC2_4_9',\n",
       "  'RC2_6_1',\n",
       "  'RC2_6_10',\n",
       "  'RC2_6_2',\n",
       "  'RC2_6_3',\n",
       "  'RC2_6_4',\n",
       "  'RC2_6_5',\n",
       "  'RC2_6_6',\n",
       "  'RC2_6_7',\n",
       "  'RC2_6_8',\n",
       "  'RC2_6_9',\n",
       "  'RC2_8_1',\n",
       "  'RC2_8_10',\n",
       "  'RC2_8_2',\n",
       "  'RC2_8_3',\n",
       "  'RC2_8_4',\n",
       "  'RC2_8_5',\n",
       "  'RC2_8_6',\n",
       "  'RC2_8_7',\n",
       "  'RC2_8_8',\n",
       "  'RC2_8_9']}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BenchmarkInstanceGenerator.get_list_of_benchmark_instances()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408dbea3",
   "metadata": {},
   "source": [
    "Ok! Now we instanciate the `generator` selection two of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6eeb80cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = BenchmarkInstanceGenerator(instance_type='Solomon', set_of_instances={'C101', 'C102'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e60b5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_c101 = generator.get_instance('C101')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b4f50cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['name', 'num_agents', 'num_nodes', 'data', 'n_digits'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance_c101.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ae8ce78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C101'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance_c101['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e5ae8ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance_c101['num_agents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4bf290c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance_c101['num_nodes']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44070687",
   "metadata": {},
   "source": [
    "By customizing `.sample_instance` method arguments, it is possible to sample a sub-instance of the original instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81e34566",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = generator.sample_instance(num_agents=3, num_nodes=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ffe50e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C101_samp'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c2c05616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance['num_agents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0175b9df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance['num_nodes']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f821778f",
   "metadata": {},
   "source": [
    "For the CVRPTW, setting `random_sample=False` we sample first `n` instace services (see  [Transportation Optimization Portal](https://www.sintef.no/projectweb/top/vrptw) for more details about `first n` Solomon benchmark\n",
    " instance):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "88b8cf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = generator.sample_instance(num_agents=3, num_nodes=8, random_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "91c39b4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C101_samp'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb2a1dd",
   "metadata": {},
   "source": [
    "###  Obervations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68f56b8",
   "metadata": {},
   "source": [
    "Observation features, that will be available to the active agent while interacting with the environment, are handle by `Observations` class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0a15a1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vrpmaenvs.environments.cvrptw.observations import Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d32d1074",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = Observations()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994e4b04",
   "metadata": {},
   "source": [
    "The class has a `default_feature_list` attribute where the default configuration dictionary is defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "23ccc7e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nodes_static': {'x_coordinate_min_max': {'feat': 'x_coordinate_min_max',\n",
       "   'norm': None},\n",
       "  'y_coordinate_min_max': {'feat': 'y_coordinate_min_max', 'norm': None}},\n",
       " 'nodes_dynamic': ['time2open_div_end_time',\n",
       "  'time2close_div_end_time',\n",
       "  'arrive2node_div_end_time'],\n",
       " 'agent': ['x_coordinate_min_max',\n",
       "  'y_coordinate_min_max',\n",
       "  'frac_current_time',\n",
       "  'frac_current_load'],\n",
       " 'other_agents': ['frac_current_time',\n",
       "  'frac_current_load',\n",
       "  'frac_feasible_nodes'],\n",
       " 'global': ['frac_demands', 'frac_fleet_load_capacity', 'frac_done_agents']}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.default_feature_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cec072",
   "metadata": {},
   "source": [
    "Also, five possible features lists exist, detailing the available features in the class: `POSSIBLE_NODES_STATIC_FEATURES`, `POSSIBLE_NODES_DYNAMIC_FEATURES`, `POSSIBLE_SELF_FEATURES`, `POSSIBLE_AGENTS_FEATURES`, `POSSIBLE_GLOBAL_FEATURES`. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "77a3cb17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x_coordinate',\n",
       " 'y_coordinate',\n",
       " 'tw_low',\n",
       " 'tw_high',\n",
       " 'demand',\n",
       " 'service_time',\n",
       " 'tw_high_minus_tw_low_div_max_dur',\n",
       " 'x_coordinate_min_max',\n",
       " 'y_coordinate_min_max',\n",
       " 'is_depot']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.POSSIBLE_NODES_STATIC_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7b9b2465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['min_agent_current_time_div_end_time',\n",
       " 'frac_demands',\n",
       " 'frac_fleet_load_capacity',\n",
       " 'frac_done_agents',\n",
       " 'frac_not_done_nodes',\n",
       " 'frac_used_agents']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.POSSIBLE_GLOBAL_FEATURES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa61f210",
   "metadata": {},
   "source": [
    "While instantiating the `Observations` class, we can pass through a feature list dictionary specifying which features will be available for the agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "87bb625b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bd7e8d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = yaml.safe_load(\"\"\"\n",
    "    nodes_static:\n",
    "        x_coordinate_min_max:\n",
    "            feat: x_coordinate_min_max\n",
    "            norm: min_max\n",
    "        x_coordinate_min_max: \n",
    "            feat: x_coordinate_min_max\n",
    "            norm: min_max\n",
    "        tw_low_mm:\n",
    "            feat: tw_low\n",
    "            norm: min_max\n",
    "        tw_high:\n",
    "            feat: tw_high\n",
    "            norm: min_max\n",
    "\n",
    "    nodes_dynamic:\n",
    "        - time2open_div_end_time\n",
    "        - time2close_div_end_time\n",
    "        - time2open_after_step_div_end_time\n",
    "        - time2close_after_step_div_end_time\n",
    "        - fract_time_after_step_div_end_time\n",
    "\n",
    "    agent:\n",
    "        - x_coordinate_min_max\n",
    "        - y_coordinate_min_max\n",
    "        - frac_current_time\n",
    "        - frac_current_load\n",
    "\n",
    "    other_agents:\n",
    "        - x_coordinate_min_max\n",
    "        - y_coordinate_min_max\n",
    "        - frac_current_time\n",
    "        - frac_current_load\n",
    "        - dist2agent_div_end_time\n",
    "    \n",
    "    global:\n",
    "        - frac_demands\n",
    "        - frac_fleet_load_capacity\n",
    "        - frac_done_agents\n",
    "        - frac_not_done_nodes\n",
    "        - frac_used_agents\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "695e9c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = Observations(feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c7bbd6",
   "metadata": {},
   "source": [
    "We can test this observations on the environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "841178da",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = InstanceGenerator(batch_size = 8)\n",
    "obs = Observations()\n",
    "sel = AgentSelector()\n",
    "rew = DenseReward()\n",
    "\n",
    "env = Environment(instance_generator_object=gen,  \n",
    "                  obs_builder_object=obs,\n",
    "                  agent_selector_object=sel,\n",
    "                  reward_evaluator=rew,\n",
    "                  seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "09332ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "td = env.reset(batch_size = 8, num_agents=4, num_nodes=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9644e544",
   "metadata": {},
   "outputs": [],
   "source": [
    "td_observation = env.observe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "704aa1c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        action_mask: Tensor(shape=torch.Size([8, 16]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        agent_obs: Tensor(shape=torch.Size([8, 4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        agents_mask: Tensor(shape=torch.Size([8, 4]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        global_obs: Tensor(shape=torch.Size([8, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        node_dynamic_obs: Tensor(shape=torch.Size([8, 16, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        node_static_obs: Tensor(shape=torch.Size([8, 16, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        other_agents_obs: Tensor(shape=torch.Size([8, 4, 3]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "    batch_size=torch.Size([8]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td_observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3b83ef",
   "metadata": {},
   "source": [
    "###  Agent Iterator class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0267064",
   "metadata": {},
   "source": [
    "Equivalent to [PettingZoo](https://pettingzoo.farama.org/), Agent Selector class incorporates the iterator method `agent_iter` that returns the next active agent in the environment. It is perfectly customizable and currently  `AgentSelector`, `SmallesttimeAgentSelector` classes are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "04d2e94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vrpmaenvs.environments.cvrptw.env_agent_selector import AgentSelector, SmallesttimeAgentSelector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8728d5f",
   "metadata": {},
   "source": [
    "With `AgentSelector` class, the selection steps through the active agents in a circular fashion, until no more active agents are available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "32319404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env step number: tensor([[1]]), active agent name: tensor([[0]])\n",
      "env step number: tensor([[2]]), active agent name: tensor([[0]])\n",
      "env step number: tensor([[3]]), active agent name: tensor([[0]])\n",
      "env step number: tensor([[4]]), active agent name: tensor([[0]])\n",
      "env step number: tensor([[5]]), active agent name: tensor([[1]])\n",
      "env step number: tensor([[6]]), active agent name: tensor([[1]])\n",
      "env step number: tensor([[7]]), active agent name: tensor([[1]])\n",
      "env step number: tensor([[8]]), active agent name: tensor([[1]])\n",
      "env step number: tensor([[9]]), active agent name: tensor([[2]])\n",
      "env step number: tensor([[10]]), active agent name: tensor([[2]])\n",
      "env step number: tensor([[11]]), active agent name: tensor([[2]])\n",
      "env step number: tensor([[12]]), active agent name: tensor([[3]])\n",
      "env step number: tensor([[13]]), active agent name: tensor([[3]])\n",
      "env step number: tensor([[14]]), active agent name: tensor([[4]])\n",
      "env step number: tensor([[15]]), active agent name: tensor([[4]])\n",
      "env step number: tensor([[16]]), active agent name: tensor([[4]])\n",
      "env step number: tensor([[17]]), active agent name: tensor([[4]])\n",
      "env step number: tensor([[18]]), active agent name: tensor([[4]])\n",
      "env step number: tensor([[19]]), active agent name: tensor([[5]])\n",
      "env step number: tensor([[20]]), active agent name: tensor([[5]])\n",
      "env step number: tensor([[21]]), active agent name: tensor([[5]])\n",
      "env step number: tensor([[22]]), active agent name: tensor([[5]])\n",
      "env step number: tensor([[23]]), active agent name: tensor([[6]])\n",
      "env step number: tensor([[24]]), active agent name: tensor([[6]])\n",
      "env step number: tensor([[25]]), active agent name: tensor([[6]])\n",
      "env step number: tensor([[26]]), active agent name: tensor([[7]])\n",
      "env step number: tensor([[27]]), active agent name: tensor([[7]])\n",
      "env step number: tensor([[28]]), active agent name: tensor([[7]])\n",
      "env step number: tensor([[29]]), active agent name: tensor([[7]])\n",
      "env step number: tensor([[30]]), active agent name: tensor([[8]])\n",
      "env step number: tensor([[31]]), active agent name: tensor([[8]])\n",
      "env step number: tensor([[32]]), active agent name: tensor([[8]])\n",
      "env step number: tensor([[33]]), active agent name: tensor([[8]])\n",
      "env step number: tensor([[34]]), active agent name: tensor([[9]])\n",
      "env step number: tensor([[35]]), active agent name: tensor([[9]])\n",
      "env step number: tensor([[36]]), active agent name: tensor([[9]])\n",
      "env step number: tensor([[37]]), active agent name: tensor([[9]])\n",
      "env step number: tensor([[38]]), active agent name: tensor([[9]])\n",
      "env step number: tensor([[39]]), active agent name: tensor([[10]])\n",
      "env step number: tensor([[40]]), active agent name: tensor([[10]])\n",
      "env step number: tensor([[41]]), active agent name: tensor([[10]])\n",
      "env step number: tensor([[42]]), active agent name: tensor([[10]])\n",
      "env step number: tensor([[43]]), active agent name: tensor([[10]])\n",
      "env step number: tensor([[44]]), active agent name: tensor([[11]])\n",
      "env step number: tensor([[45]]), active agent name: tensor([[11]])\n",
      "env step number: tensor([[46]]), active agent name: tensor([[11]])\n",
      "env step number: tensor([[47]]), active agent name: tensor([[11]])\n",
      "env step number: tensor([[48]]), active agent name: tensor([[12]])\n",
      "env step number: tensor([[49]]), active agent name: tensor([[12]])\n",
      "env step number: tensor([[50]]), active agent name: tensor([[12]])\n",
      "env step number: tensor([[51]]), active agent name: tensor([[12]])\n",
      "env step number: tensor([[52]]), active agent name: tensor([[13]])\n",
      "env step number: tensor([[53]]), active agent name: tensor([[13]])\n",
      "env step number: tensor([[54]]), active agent name: tensor([[13]])\n",
      "env step number: tensor([[55]]), active agent name: tensor([[14]])\n",
      "env step number: tensor([[56]]), active agent name: tensor([[14]])\n",
      "env step number: tensor([[57]]), active agent name: tensor([[14]])\n",
      "env step number: tensor([[58]]), active agent name: tensor([[14]])\n",
      "env step number: tensor([[59]]), active agent name: tensor([[15]])\n",
      "env step number: tensor([[60]]), active agent name: tensor([[16]])\n",
      "env step number: tensor([[61]]), active agent name: tensor([[16]])\n",
      "env step number: tensor([[62]]), active agent name: tensor([[16]])\n",
      "env step number: tensor([[63]]), active agent name: tensor([[16]])\n",
      "env step number: tensor([[64]]), active agent name: tensor([[17]])\n",
      "env step number: tensor([[65]]), active agent name: tensor([[17]])\n",
      "env step number: tensor([[66]]), active agent name: tensor([[17]])\n",
      "env step number: tensor([[67]]), active agent name: tensor([[17]])\n",
      "env step number: tensor([[68]]), active agent name: tensor([[18]])\n",
      "env step number: tensor([[69]]), active agent name: tensor([[18]])\n",
      "env step number: tensor([[70]]), active agent name: tensor([[19]])\n",
      "env step number: tensor([[71]]), active agent name: tensor([[19]])\n",
      "env step number: tensor([[72]]), active agent name: tensor([[19]])\n",
      "env step number: tensor([[73]]), active agent name: tensor([[0]])\n"
     ]
    }
   ],
   "source": [
    "gen = InstanceGenerator(batch_size = 1)\n",
    "obs = Observations()\n",
    "sel = AgentSelector()\n",
    "rew = DenseReward()\n",
    "\n",
    "env = Environment(instance_generator_object=gen,  \n",
    "                  obs_builder_object=obs,\n",
    "                  agent_selector_object=sel,\n",
    "                  reward_evaluator=rew,\n",
    "                  seed=0)\n",
    "\n",
    "td = env.reset()\n",
    "\n",
    "while not td[\"done\"].all():  \n",
    "    td = env.sample_action(td) # this is where we insert our policy\n",
    "    td = env.step(td)\n",
    "    step = td['step']\n",
    "    cur_agent_idx = td['cur_agent_idx']\n",
    "    print(f'env step number: {step}, active agent name: {cur_agent_idx}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef431706",
   "metadata": {},
   "source": [
    "With `SmallesttimeAgentSelector` class, the same agent is  select until it returns to the depot. Afterward, it selects the next active agent and repeats the process until all agents are done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b1ce3b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env step number: tensor([[1]]), active agent name: tensor([[1]])\n",
      "env step number: tensor([[2]]), active agent name: tensor([[2]])\n",
      "env step number: tensor([[3]]), active agent name: tensor([[3]])\n",
      "env step number: tensor([[4]]), active agent name: tensor([[4]])\n",
      "env step number: tensor([[5]]), active agent name: tensor([[5]])\n",
      "env step number: tensor([[6]]), active agent name: tensor([[6]])\n",
      "env step number: tensor([[7]]), active agent name: tensor([[7]])\n",
      "env step number: tensor([[8]]), active agent name: tensor([[8]])\n",
      "env step number: tensor([[9]]), active agent name: tensor([[9]])\n",
      "env step number: tensor([[10]]), active agent name: tensor([[10]])\n",
      "env step number: tensor([[11]]), active agent name: tensor([[11]])\n",
      "env step number: tensor([[12]]), active agent name: tensor([[12]])\n",
      "env step number: tensor([[13]]), active agent name: tensor([[13]])\n",
      "env step number: tensor([[14]]), active agent name: tensor([[14]])\n",
      "env step number: tensor([[15]]), active agent name: tensor([[15]])\n",
      "env step number: tensor([[16]]), active agent name: tensor([[16]])\n",
      "env step number: tensor([[17]]), active agent name: tensor([[17]])\n",
      "env step number: tensor([[18]]), active agent name: tensor([[18]])\n",
      "env step number: tensor([[19]]), active agent name: tensor([[19]])\n",
      "env step number: tensor([[20]]), active agent name: tensor([[0]])\n",
      "env step number: tensor([[21]]), active agent name: tensor([[14]])\n",
      "env step number: tensor([[22]]), active agent name: tensor([[8]])\n",
      "env step number: tensor([[23]]), active agent name: tensor([[13]])\n",
      "env step number: tensor([[24]]), active agent name: tensor([[11]])\n",
      "env step number: tensor([[25]]), active agent name: tensor([[3]])\n",
      "env step number: tensor([[26]]), active agent name: tensor([[16]])\n",
      "env step number: tensor([[27]]), active agent name: tensor([[17]])\n",
      "env step number: tensor([[28]]), active agent name: tensor([[7]])\n",
      "env step number: tensor([[29]]), active agent name: tensor([[18]])\n",
      "env step number: tensor([[30]]), active agent name: tensor([[1]])\n",
      "env step number: tensor([[31]]), active agent name: tensor([[15]])\n",
      "env step number: tensor([[32]]), active agent name: tensor([[16]])\n",
      "env step number: tensor([[33]]), active agent name: tensor([[4]])\n",
      "env step number: tensor([[34]]), active agent name: tensor([[8]])\n",
      "env step number: tensor([[35]]), active agent name: tensor([[14]])\n",
      "env step number: tensor([[36]]), active agent name: tensor([[17]])\n",
      "env step number: tensor([[37]]), active agent name: tensor([[6]])\n",
      "env step number: tensor([[38]]), active agent name: tensor([[10]])\n",
      "env step number: tensor([[39]]), active agent name: tensor([[2]])\n",
      "env step number: tensor([[40]]), active agent name: tensor([[7]])\n",
      "env step number: tensor([[41]]), active agent name: tensor([[1]])\n",
      "env step number: tensor([[42]]), active agent name: tensor([[3]])\n",
      "env step number: tensor([[43]]), active agent name: tensor([[5]])\n",
      "env step number: tensor([[44]]), active agent name: tensor([[0]])\n",
      "env step number: tensor([[45]]), active agent name: tensor([[11]])\n",
      "env step number: tensor([[46]]), active agent name: tensor([[18]])\n",
      "env step number: tensor([[47]]), active agent name: tensor([[8]])\n",
      "env step number: tensor([[48]]), active agent name: tensor([[17]])\n",
      "env step number: tensor([[49]]), active agent name: tensor([[1]])\n",
      "env step number: tensor([[50]]), active agent name: tensor([[13]])\n",
      "env step number: tensor([[51]]), active agent name: tensor([[9]])\n",
      "env step number: tensor([[52]]), active agent name: tensor([[15]])\n",
      "env step number: tensor([[53]]), active agent name: tensor([[10]])\n",
      "env step number: tensor([[54]]), active agent name: tensor([[6]])\n",
      "env step number: tensor([[55]]), active agent name: tensor([[4]])\n",
      "env step number: tensor([[56]]), active agent name: tensor([[11]])\n",
      "env step number: tensor([[57]]), active agent name: tensor([[7]])\n",
      "env step number: tensor([[58]]), active agent name: tensor([[14]])\n",
      "env step number: tensor([[59]]), active agent name: tensor([[0]])\n",
      "env step number: tensor([[60]]), active agent name: tensor([[12]])\n",
      "env step number: tensor([[61]]), active agent name: tensor([[19]])\n",
      "env step number: tensor([[62]]), active agent name: tensor([[8]])\n",
      "env step number: tensor([[63]]), active agent name: tensor([[3]])\n",
      "env step number: tensor([[64]]), active agent name: tensor([[17]])\n",
      "env step number: tensor([[65]]), active agent name: tensor([[5]])\n",
      "env step number: tensor([[66]]), active agent name: tensor([[16]])\n",
      "env step number: tensor([[67]]), active agent name: tensor([[10]])\n",
      "env step number: tensor([[68]]), active agent name: tensor([[2]])\n",
      "env step number: tensor([[69]]), active agent name: tensor([[13]])\n",
      "env step number: tensor([[70]]), active agent name: tensor([[19]])\n",
      "env step number: tensor([[71]]), active agent name: tensor([[7]])\n",
      "env step number: tensor([[72]]), active agent name: tensor([[1]])\n",
      "env step number: tensor([[73]]), active agent name: tensor([[0]])\n"
     ]
    }
   ],
   "source": [
    "gen = InstanceGenerator(batch_size = 1)\n",
    "obs = Observations()\n",
    "sel = SmallesttimeAgentSelector()\n",
    "rew = DenseReward()\n",
    "\n",
    "env = Environment(instance_generator_object=gen,  \n",
    "                  obs_builder_object=obs,\n",
    "                  agent_selector_object=sel,\n",
    "                  reward_evaluator=rew,\n",
    "                  seed=0)\n",
    "\n",
    "td = env.reset()\n",
    "\n",
    "while not td[\"done\"].all():  \n",
    "    td = env.sample_action(td) # this is where we insert our policy\n",
    "    td = env.step(td)\n",
    "    step = td['step']\n",
    "    cur_agent_idx = td['cur_agent_idx']\n",
    "    print(f'env step number: {step}, active agent name: {cur_agent_idx}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl4vrp_env",
   "language": "python",
   "name": "rl4vrp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
